# Spark

Increasingly Data Scientists are expected to know at least the fundamentals of building web-scale, cloud-based applications. This notebook demonstrates the fundamentals of Spark, the most popular tool used today to build Data Science distributed applications at scale.


### Key Terms & Concepts

* **Big Data:** Algorithms and technology associated with storing and manipulating data sets that are typically too large to fit in the memory of a single machine

* **Resilient distributed datasets:** A data structure in Spark which is persistent (i.e. is saved to disk and can be retrieved whether or not it's currently in memory) and can be shared across machines

* **Transformations:** Mathematical operations performed on data

* **Commutative Functions:** A mathematical function with two arguments whose order can be reversed with the same result. For example, adding two numbers is a commutative operation i.e. 1 + 2 produces the same result as 2 + 1.

* **Associative Functions:** A mathematical function with two arguments, where a series of applications of the function produced the same result regardless of the part of the sequence executed first. For example, multiplication is associative i.e. 2*3*4 can be evaluated as (2*3)*4 or 2*(3*4) with the same result


