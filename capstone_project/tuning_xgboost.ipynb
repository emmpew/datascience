{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning XGBoost\n",
    "***\n",
    "In this notebook, let's build a gradient boosting regression to predict a NYC taxi trip duration given the **cleaned data** of taxi trips from 2016. The original data can be found in [kaggle's competition](https://www.kaggle.com/c/nyc-taxi-trip-duration/data). The data wrangling, exploratory data analysis and data cleaning can be found in [this](https://github.com/emmpew/datascience/blob/master/capstone_project/nyc_trip_duration.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "***\n",
    "Load the cleaned data that is ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('cleaned_train_data.csv')\n",
    "test = pd.read_csv('cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "test.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('trip_duration',axis=1)\n",
    "y_train = train['trip_duration']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "***\n",
    "\n",
    "XGBoost has more than 20 parameters to tune. Tuning more parameters usually gives better results; however, it does become computationally expensive and time consuming. For this project, let's focus on the following 5 paramenters:\n",
    "\n",
    "- n_estimators\n",
    "- max_depth\n",
    "- min_child_weight\n",
    "- subsample\n",
    "- colsample_bytree\n",
    "\n",
    "To validate the model, let's use cross-validation so that the metrics have a more precise estimate, in this case [Root Mean Squared Logarithmic Error](https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError). Due to the large amount of data(~1.4 million entries), let's split our data only in 5 folds. This means that cross-validation will be 5x as expensive as fitting a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true,y_pred):\n",
    "   assert len(y_true) == len(y_pred)\n",
    "   return np.square(np.log(y_pred + 1) - np.log(y_true + 1)).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tunning(params):\n",
    "    xgboost_cv = GridSearchCV(XGBRegressor(),params, cv=5,verbose=3)\n",
    "    %time xgboost_cv.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = xgboost_cv.predict(X_test)\n",
    "    metric = rmsle(y_test,y_pred)\n",
    "\n",
    "    print(\"Best Parameters: {}\".format(xgboost_cv.best_params_)) \n",
    "    print(\"Best score is {}\".format(xgboost_cv.best_score_))\n",
    "    print(\"RMSLE is {}\".format(metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators\n",
    "\n",
    "This parameter sets the number of boosted trees to fit. Each weak learner(tree) improves from the previous one. So the more you have, the more it will learn. However, there is a certain threshold were the model will stop learning and will only be noise. Also, the higher n_estimators, the more computantionally expensive it becomes. So for this case let's just use 3 different values for the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] ........ n_estimators=10, score=0.3727455669785603, total=   8.2s\n",
      "[CV] n_estimators=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... n_estimators=10, score=0.37256353522029295, total=   8.2s\n",
      "[CV] n_estimators=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ n_estimators=10, score=0.3680092828338972, total=   7.9s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] ....... n_estimators=10, score=0.37146510068102323, total=   8.2s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] ....... n_estimators=10, score=0.37314683753481626, total=   8.1s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=0.6905727837114519, total=  22.3s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=0.6942748936703185, total=  22.4s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=0.6788522645289554, total=  22.8s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=0.6921605492682087, total=  22.3s\n",
      "[CV] n_estimators=30 .................................................\n",
      "[CV] ........ n_estimators=30, score=0.6914725671970348, total=  22.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.7170908636236757, total=  36.7s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.7210974911657331, total=  36.8s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.7046530894377585, total=  36.5s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.7199425245367495, total=  36.9s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ........ n_estimators=50, score=0.7169474908164117, total=  37.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 31s, sys: 3.75 s, total: 6min 35s\n",
      "Wall time: 6min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50}\n",
      "Best score is 0.7159462981176532\n",
      "RMSLE is 0.44678453304116034\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [10,30,50]}\n",
    "\n",
    "hyperparameter_tunning(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shows that using 50 n_estimators will give better results. \n",
    "\n",
    "### max_depth\n",
    "\n",
    "This parameters  is the maximum number of nodes allowed from the root to the farthest leaf of a tree.  This means that the more nodes we add the more complex relationships the algorithm can model; however, at some point splits become less relevant causing the model to overfit. Let's use best parameters found so far plus 3 different max_depth values to tune the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV]  max_depth=2, n_estimators=50, score=0.690850157154514, total=  24.8s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, n_estimators=50, score=0.6944858128369444, total=  24.6s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   51.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, n_estimators=50, score=0.6790032257249099, total=  25.0s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV]  max_depth=2, n_estimators=50, score=0.6931945834340137, total=  24.9s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV]  max_depth=2, n_estimators=50, score=0.6907898362754823, total=  24.7s\n",
      "[CV] max_depth=5, n_estimators=50 ....................................\n",
      "[CV]  max_depth=5, n_estimators=50, score=0.7527919516031409, total= 1.0min\n",
      "[CV] max_depth=5, n_estimators=50 ....................................\n",
      "[CV]  max_depth=5, n_estimators=50, score=0.7570808032205429, total= 1.0min\n",
      "[CV] max_depth=5, n_estimators=50 ....................................\n",
      "[CV]  max_depth=5, n_estimators=50, score=0.7406796889876259, total= 1.0min\n",
      "[CV] max_depth=5, n_estimators=50 ....................................\n",
      "[CV]  max_depth=5, n_estimators=50, score=0.7551514344485716, total= 1.0min\n",
      "[CV] max_depth=5, n_estimators=50 ....................................\n",
      "[CV]  max_depth=5, n_estimators=50, score=0.7524012936426832, total= 1.0min\n",
      "[CV] max_depth=8, n_estimators=50 ....................................\n",
      "[CV]  max_depth=8, n_estimators=50, score=0.7885929871681004, total= 1.8min\n",
      "[CV] max_depth=8, n_estimators=50 ....................................\n",
      "[CV]  max_depth=8, n_estimators=50, score=0.7923856041021791, total= 1.7min\n",
      "[CV] max_depth=8, n_estimators=50 ....................................\n",
      "[CV]  max_depth=8, n_estimators=50, score=0.7767220173484114, total= 1.8min\n",
      "[CV] max_depth=8, n_estimators=50 ....................................\n",
      "[CV]  max_depth=8, n_estimators=50, score=0.7918139364548393, total= 1.7min\n",
      "[CV] max_depth=8, n_estimators=50 ....................................\n",
      "[CV]  max_depth=8, n_estimators=50, score=0.7881689793268866, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 44s, sys: 4.39 s, total: 18min 49s\n",
      "Wall time: 18min 49s\n",
      "Best Parameters: {'max_depth': 8, 'n_estimators': 50}\n",
      "Best score is 0.7875367106969244\n",
      "RMSLE is 0.38458887312586937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': [2,5,8],\n",
    "          'n_estimators': [50]}\n",
    "\n",
    "hyperparameter_tunning(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result show that with 50 n_estimators the best max_depth is 8. Tuning only two parameters the RMSLE lowered to 0.3845.\n",
    "\n",
    "### min_child_weight\n",
    "\n",
    "This parameter refers to the minimum number of samples required to create a new node in a tree. If the value is lower, the algorithm can create children that correspond to fewer samples. Let's use best parameters found so far plus 3 different min_child_weight values to tune the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] max_depth=8, min_child_weight=5, n_estimators=50 ................\n",
      "[CV]  max_depth=8, min_child_weight=5, n_estimators=50, score=0.7894004515262651, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=5, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, min_child_weight=5, n_estimators=50, score=0.7931386224969376, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=5, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, min_child_weight=5, n_estimators=50, score=0.7754018449843321, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=5, n_estimators=50 ................\n",
      "[CV]  max_depth=8, min_child_weight=5, n_estimators=50, score=0.7937147333142706, total= 2.0min\n",
      "[CV] max_depth=8, min_child_weight=5, n_estimators=50 ................\n",
      "[CV]  max_depth=8, min_child_weight=5, n_estimators=50, score=0.787488377372252, total= 2.1min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, score=0.789561872871535, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, score=0.7935840519014963, total= 2.0min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, score=0.7760214244924619, total= 2.1min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, score=0.7934696054339088, total= 2.1min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, score=0.7882809190422652, total= 2.2min\n",
      "[CV] max_depth=8, min_child_weight=15, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=15, n_estimators=50, score=0.7883145225893596, total= 2.3min\n",
      "[CV] max_depth=8, min_child_weight=15, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=15, n_estimators=50, score=0.7928078862740925, total= 2.1min\n",
      "[CV] max_depth=8, min_child_weight=15, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=15, n_estimators=50, score=0.7762506967935632, total= 2.1min\n",
      "[CV] max_depth=8, min_child_weight=15, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=15, n_estimators=50, score=0.7934826246621091, total= 2.0min\n",
      "[CV] max_depth=8, min_child_weight=15, n_estimators=50 ...............\n",
      "[CV]  max_depth=8, min_child_weight=15, n_estimators=50, score=0.7878603920946087, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 31.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min, sys: 15.2 s, total: 33min 16s\n",
      "Wall time: 33min 48s\n",
      "Best Parameters: {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 50}\n",
      "Best score is 0.7881835814256996\n",
      "RMSLE is 0.38403234174560336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "params = {'min_child_weight': [5,10,15],\n",
    "          'max_depth': [8],\n",
    "          'n_estimators': [50]}\n",
    "\n",
    "hyperparameter_tunning(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 50 n_estimators and max_child_weight of 8, the best min_child_weight is 10. The improvement in RMSLE was only **0.0005**, with a value of 0.3840. \n",
    "\n",
    "### subsample\n",
    "\n",
    "This parameter is to determine the fraction of entries(rows) to subsample at each step. Let's use best parameters found so far plus 3 different subsample values to tune the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4, score=0.7890842694634209, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4, score=0.793275202285739, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4, score=0.7740062049358123, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4, score=0.7916775420192559, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.4, score=0.787144919877181, total= 1.7min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6, score=0.7887579594180926, total= 1.7min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6, score=0.7926183299878203, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6, score=0.7768341424429359, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6, score=0.7922248068001795, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.6, score=0.7870263471941821, total= 2.0min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8, score=0.789630992438309, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8, score=0.7928816734044937, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8, score=0.7757699237331867, total= 1.9min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8, score=0.7931069972264906, total= 1.8min\n",
      "[CV] max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8 \n",
      "[CV]  max_depth=8, min_child_weight=10, n_estimators=50, subsample=0.8, score=0.7872994364641689, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 28.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 6s, sys: 15 s, total: 30min 21s\n",
      "Wall time: 30min 44s\n",
      "Best Parameters: {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Best score is 0.7877378115851132\n",
      "RMSLE is 0.38542680033216076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "params = {'subsample': [0.4,0.6,0.8],\n",
    "          'min_child_weight': [10],\n",
    "          'max_depth': [8],\n",
    "          'n_estimators': [50]}\n",
    "\n",
    "hyperparameter_tunning(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE went up that means that the default value (1.0) for subsample is the best option.\n",
    "\n",
    "## colsample_bytree\n",
    "\n",
    "This parameter is to choose the fraction of features that the algorithm will use. Remember that some features are more useful than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7865058686107766, total= 1.4min\n",
      "[CV] colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50, score=0.791446645043126, total= 1.4min\n",
      "[CV] colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7739798142219648, total= 2.0min\n",
      "[CV] colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7900780408808624, total= 1.5min\n",
      "[CV] colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.8, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7855123433603144, total= 1.5min\n",
      "[CV] colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50, score=0.78851208153541, total= 1.6min\n",
      "[CV] colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7928138230903431, total= 1.6min\n",
      "[CV] colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7764854544827181, total= 1.7min\n",
      "[CV] colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7922096551790859, total= 1.7min\n",
      "[CV] colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=0.9, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7862740743460379, total= 1.6min\n",
      "[CV] colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50, score=0.789561872871535, total= 1.9min\n",
      "[CV] colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7935840519014963, total= 1.9min\n",
      "[CV] colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7760214244924619, total= 1.8min\n",
      "[CV] colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7934696054339088, total= 1.9min\n",
      "[CV] colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50 \n",
      "[CV]  colsample_bytree=1.0, max_depth=8, min_child_weight=10, n_estimators=50, score=0.7882809190422652, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 26.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 18s, sys: 15.7 s, total: 28min 34s\n",
      "Wall time: 29min 1s\n",
      "Best Parameters: {'colsample_bytree': 1.0, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 50}\n",
      "Best score is 0.7881835814256996\n",
      "RMSLE is 0.38403234174560336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': [0.8,0.9,1.0],\n",
    "          'min_child_weight': [10],\n",
    "          'max_depth': [8],\n",
    "          'n_estimators': [50]}\n",
    "\n",
    "hyperparameter_tunning(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value for colsample_bytree was the default 1.0. RMSLE remained at **0.3840** making it the best result tuning only 5 parameters with 5 folds.\n",
    "\n",
    "\n",
    "## Results\n",
    "***\n",
    "After more than 2 hours of tuning, only 5 hyperparameters were explored. XGBoost is a powerful ensemble model; however, it is computationally expensive. The best hyperparameter values found were the following:\n",
    "\n",
    "- n_estimators: 50\n",
    "- max_depth: 8\n",
    "- min_child_weight: 10\n",
    "- subsample: 1.0 (default value)\n",
    "- colsample_bytree: 1.0 (default value)\n",
    "\n",
    "The best RMSLE was **0.3840**. There is more that this powerful algorithm can do. For this project, this was a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
